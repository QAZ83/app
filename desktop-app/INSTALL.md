# ๐ AI Forge Studio - Desktop Application
## ุฏููู ุงูุชุซุจูุช ูุงูุชุดุบูู

---

## ๐ ุงููุชุทูุจุงุช

### ุงูุฃุณุงุณูุฉ:
- **Windows 10/11** (64-bit)
- **Python 3.10+**
- **Node.js 18+**
- **NVIDIA GPU** (RTX 20xx ุฃู ุฃุญุฏุซ)

### ููููุฒุงุช ุงููุชูุฏูุฉ:
- **NVIDIA Driver** 535+ (ููุฑุงุกุฉ GPU)
- **CUDA Toolkit 12.x** (ููู Benchmarks)
- **cuDNN 8.x** (ููู Inference)
- **TensorRT 8.x** (Optional - ูุชุณุฑูุน ุฅุถุงูู)

---

## ๐ฅ ุฎุทูุงุช ุงูุชุซุจูุช

### 1๏ธโฃ ุชุซุจูุช NVIDIA Driver
```bash
# ุชุญูู ูู ุฅุตุฏุงุฑ ุงูุชุนุฑูู
nvidia-smi

# ุฅุฐุง ูุงู ุงูุฅุตุฏุงุฑ ุฃูุฏู ูู 535ุ ุญุฏุซู ูู:
# https://www.nvidia.com/Download/index.aspx
```

### 2๏ธโฃ ุชุซุจูุช CUDA Toolkit
```bash
# ุชูุฒูู CUDA 12.x ูู:
# https://developer.nvidia.com/cuda-downloads

# ุจุนุฏ ุงูุชุซุจูุชุ ุชุญูู:
nvcc --version
```

### 3๏ธโฃ ุชุซุจูุช Python Dependencies
```bash
cd backend

# ุฅูุดุงุก ุจูุฆุฉ ุงูุชุฑุงุถูุฉ (ูุณุชุญุณู)
python -m venv venv
venv\Scripts\activate  # Windows
# source venv/bin/activate  # Linux/Mac

# ุชุซุจูุช ุงูููุชุจุงุช ุงูุฃุณุงุณูุฉ
pip install fastapi uvicorn pydantic python-dotenv

# ุชุซุจูุช ูุฑุงูุจุฉ GPU
pip install pynvml

# ุชุซุจูุช CUDA Computing (ุญุณุจ ุฅุตุฏุงุฑ CUDA)
pip install cupy-cuda12x  # ูู CUDA 12.x
# pip install cupy-cuda11x  # ูู CUDA 11.x

# ุชุซุจูุช AI Inference
pip install onnxruntime-gpu  # ูู GPU
# pip install onnxruntime  # ููู CPU ููุท

# ุชุซุจูุช ูุณุงุนุฏ AI (ุงุฎุชูุงุฑู)
pip install emergentintegrations --extra-index-url https://d33sy5i8bnduwe.cloudfront.net/simple/
```

### 4๏ธโฃ ุชุซุจูุช Electron Dependencies
```bash
cd ..
npm install
# ุฃู
yarn install
```

---

## โถ๏ธ ุงูุชุดุบูู

### ูุถุน ุงูุชุทููุฑ:
```bash
# ุชุดุบูู ุงูู Backend ูููุตูุงู
cd backend
python -m uvicorn server:app --host 127.0.0.1 --port 8080 --reload

# ูู terminal ุขุฎุฑุ ุชุดุบูู Electron
npm run dev
```

### ูุถุน ุงูุฅูุชุงุฌ:
```bash
npm start
```

---

## ๐ฆ ุจูุงุก ููู .exe

### ุจูุงุก ูู Windows:
```bash
npm run build:win
```

### ุงููููุงุช ุงููุงุชุฌุฉ:
- `dist/AI Forge Studio-2.0.0-x64.exe` - ููู ุงูุชุซุจูุช (NSIS)
- `dist/AI Forge Studio-2.0.0-x64.portable.exe` - ูุณุฎุฉ ูุญูููุฉ

---

## ๐ ูููู ุงููุดุฑูุน

```
ai-forge-studio/
โโโ package.json          # Electron config
โโโ main.js               # Electron main process
โโโ preload.js            # Electron preload script
โโโ backend/              # Python FastAPI backend
โ   โโโ server.py         # Main API server
โ   โโโ gpu_monitor.py    # GPU monitoring (pynvml)
โ   โโโ benchmarks.py     # CUDA benchmarks
โ   โโโ inference.py      # AI inference
โ   โโโ requirements.txt
โโโ renderer/             # React frontend
โ   โโโ src/
โ   โโโ index.html
โโโ assets/               # Icons, images
โโโ models/               # ONNX models directory
```

---

## ๐ง ุงูุฅุนุฏุงุฏุงุช

### ููู config.json:
```json
{
  "models_directory": "C:\\Models",
  "display_resolution": "1920x1080",
  "enable_gpu_animations": true,
  "default_ai_model": "gpt-4o-mini",
  "ai_provider": "openai",
  "api_key": "your-api-key-here",
  "theme": "dark",
  "language": "ar",
  "auto_refresh_interval": 2000
}
```

### ููุชุงุญ AI API:
ูุชูุนูู ูุณุงุนุฏ ุงูุฐูุงุก ุงูุงุตุทูุงุนู:
1. ุงุฐูุจ ุฅูู ุงูุฅุนุฏุงุฏุงุช
2. ุฃุฏุฎู ููุชุงุญ OpenAI ุฃู Emergent LLM Key
3. ุงุญูุธ ุงูุฅุนุฏุงุฏุงุช

---

## ๐ฎ ุงูููุฒุงุช

### โ ูุฑุงูุจุฉ GPU ุญููููุฉ:
- ุฏุฑุฌุฉ ุงูุญุฑุงุฑุฉ
- ุงุณุชุฎุฏุงู GPU/ุงูุฐุงูุฑุฉ
- ุงุณุชููุงู ุงูุทุงูุฉ
- ุณุฑุนุฉ ุงูุณุงุนุฉ/ุงููุฑูุญุฉ
- ูุนูููุงุช PCIe

### โ ุงุฎุชุจุงุฑุงุช ุฃุฏุงุก ุญููููุฉ:
- **CUDA Benchmark**: ุถุฑุจ ูุตูููุงุช ูููุงุณ GFLOPS
- **Memory Bandwidth**: ููุงุณ ุณุฑุนุฉ ุงูุฐุงูุฑุฉ
- **Tensor Core**: ุงุฎุชุจุงุฑ FP16 TFLOPS

### โ ุงุณุชุฏูุงู AI ุญูููู:
- ุชุญููู ููุงุฐุฌ ONNX
- ุชุดุบูู ุจุฏูุฉ FP32/FP16/INT8
- ููุงุณ Latency ู Throughput

### โ ูุณุงุนุฏ AI:
- ูุญุงุฏุซุฉ ุฐููุฉ
- ุชุญููู ูุชุงุฆุฌ ุงูุงุฎุชุจุงุฑุงุช
- ุงูุชุฑุงุญุงุช ูุชุญุณูู ุงูุฃุฏุงุก

---

## โ๏ธ ุญู ุงููุดุงูู

### ูุง ูุธูุฑ GPU:
```bash
# ุชุญูู ูู ุงูุชุนุฑูู
nvidia-smi

# ุชุญูู ูู pynvml
python -c "import pynvml; pynvml.nvmlInit(); print('OK')"
```

### CUDA ูุง ูุนูู:
```bash
# ุชุญูู ูู ุงูุชุซุจูุช
nvcc --version

# ุชุญูู ูู cupy
python -c "import cupy; print(cupy.cuda.runtime.getDeviceCount())"
```

### ุงูู Backend ูุง ูุจุฏุฃ:
```bash
# ุชุดุบูู ูุฏูู ูุฑุคูุฉ ุงูุฃุฎุทุงุก
cd backend
python -m uvicorn server:app --host 127.0.0.1 --port 8080
```

---

## ๐ ุงูุฏุนู

ูููุณุงุนุฏุฉ ุฃู ุงูุฅุจูุงุบ ุนู ูุดุงูู:
- GitHub Issues
- ูุณุงุนุฏ AI ุฏุงุฎู ุงูุชุทุจูู

---

**ุชู ุจูุงุคู ุจูุงุณุทุฉ AI Forge Studio Team** ๐
